{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: The internet: mind-and-brain.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "The ‘Doctoral alumni’ page at the website for the Berlin School of Mind and \n",
    "Brain lists the school’s former PhD students: \n",
    "http://www.mind-and-brain.de/people/doctoral-alumni/. \n",
    "\n",
    "The following Python program retrieves the details of these alumni from the \n",
    "current version of the web page and saves their information into a spreadsheet \n",
    "file. The spreadsheet contains the following information from the alumni's \n",
    "detail view: title of their doctoral project, description of their doctoral \n",
    "project, list of supervisors, cohort year, and URLs of any websites they have \n",
    "listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author: Angela Lazova\n",
    "Student ID: xxxxxx (School of Mind and Brain, Track Brain, Cohort 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ____________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Library\n",
    "We need to install BeautifulSoup external library (bs4). It can be done with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\conda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\conda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\conda\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Installing external library\n",
    "\n",
    "!pip install bs4\n",
    "\n",
    "# or alternative\n",
    "# 'conda install bs4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules and libraries\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving HTML data from website using BeautifulSoup\n",
    "\n",
    "r  = requests.get(\"http://www.mind-and-brain.de/people/doctoral-alumni/\")\n",
    "data = r.text\n",
    "\n",
    "soup = BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the alumni's names from the file\n",
    "names = []\n",
    "\n",
    "for div in soup.findAll('div', attrs={'class':'students-list-item-full-name'}):\n",
    "    names.append(div.findAll('a')[0].text.strip())\n",
    "    \n",
    "# Extracting information from the tables\n",
    "all_tables = []\n",
    "doc_projects = []\n",
    "descriptions = []\n",
    "supervisors = []\n",
    "cohort = []\n",
    "urls = []\n",
    "\n",
    "maindiv = soup.find('div', attrs={'class': 'students-list-container'}) # defining the main div where information is stored\n",
    "\n",
    "for div in maindiv.findAll('div', attrs={'class':'col col-2'}): \n",
    "    t = div.findAll('table')  # <--- contains divs classified as tables but are empty\n",
    "    if len(t) == 1:   # this is why I filter the list to include only the tables that contain information \n",
    "        all_tables.append(t[0]) # create list of all tables\n",
    "\n",
    "for a in all_tables:  # go through each table\n",
    "    allrows = a.findAll(\"tr\")  # find all rows for each table at a time\n",
    "    \n",
    "    for b in allrows: # go through all rows \n",
    "    \n",
    "    # Check if the row is something we need and add it to the list\n",
    "        if 'Doctoral project</th>' in str(b):\n",
    "            doc_projects.append(b.findAll('td')[0].text.strip())\n",
    "        elif 'Description</th>' in str(b):\n",
    "            descriptions.append(b.findAll('td')[0].text.strip()) \n",
    "        elif 'Supervisors</th>' in str(b):\n",
    "            supervisors.append(b.findAll('td')[0].text.strip())\n",
    "        elif 'Cohort</th>' in str(b):\n",
    "            cohort.append(b.findAll('td')[0].text.strip())\n",
    "    \n",
    "    # Check if the table is missing these rows and fill 'no info' in our list.       \n",
    "    if 'Description</th>' not in str(a):\n",
    "        descriptions.append('no info.')\n",
    "        \n",
    "    if 'Cohort</th>' not in str(a):\n",
    "        cohort.append('no info.')\n",
    "    \n",
    "    # Find if the table has links and add it to the list (without emails)\n",
    "    url = a.findAll('a', attrs ={'target': \"_blank\"})\n",
    "\n",
    "    if len(url) == 0:\n",
    "        urls.append('No links.')\n",
    "    else:\n",
    "        to_add = []\n",
    "        for u in url:\n",
    "            to_add.append(u.text.strip())\n",
    "        urls.append(to_add)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data to Spreadsheet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formating the data with Pandas and extacting to csv\n",
    "\n",
    "alumni = pd.DataFrame({\n",
    "    \"names\": names,\n",
    "    \"doc_projects\": doc_projects,\n",
    "    \"descriptions\":  descriptions,\n",
    "    \"supervisors\": supervisors,\n",
    "    \"cohort\": cohort,\n",
    "    \"Links\": urls\n",
    "})\n",
    "\n",
    "alumni.to_excel(\"MindandBrain_alumni_data.xlsx\") #the file is created in the current working directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
